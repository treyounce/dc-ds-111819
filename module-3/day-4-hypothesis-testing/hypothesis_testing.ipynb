{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Agenda__\n",
    "\n",
    "- Hypothesis Testing - Why do we need them?\n",
    "\n",
    "- One or two tailed hypothesis testing? Which one we should use, when?\n",
    "\n",
    "- Discussion of significance level. It's effect on our study.\n",
    "\n",
    "- Diagnosis and understanding of possible mistakes of the study.\n",
    "\n",
    "- Seeing hypothesis testing in action\n",
    "\n",
    "- Discussion of T-distribution. Why do we start talking about T-dist?\n",
    "\n",
    "- One sample and two sample T-tests.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/sweet.jpg\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null and Alternative Hypotheses\n",
    "\n",
    "![img3](./img/img3.png)                  \n",
    "\n",
    "A toy picture of science has it that the scientist formulates a hypothesis that explains or generalizes from some set of observations, and then conducts some experiment, which will either confirm or refute that hypothesis.\n",
    "\n",
    "But this is an oversimplification of good practice. Consider the possibility that the experiment yield statistically improbable results. In that case it may well be a mistake to generalize from those results or to reject an hypothesis that doesn't predict them.\n",
    "\n",
    "Often the confirmation of some testing or **alternative hypothesis, $H_\\alpha$**, is a _relative_ affair, where it is measured against some **null hypothesis, $H_0$**.\n",
    "\n",
    "If an alternative hypothesis states that there is some significant relationship between two variables, then the null hypothesis simply states that there is no such relationship.\n",
    "\n",
    "If we're testing the function of a new drug, then the null hypothesis will say that the drug has _no effect_ on patients, or anyway no effect relative to relief of the malady the drug was designed to combat. If we're testing whether Peeps cause dementia, then the null hypothesis will say that there is _no correlation_ between Peeps consumption and rate of dementia development.\n",
    "\n",
    "In any experiment we have two statements:\n",
    "\n",
    "## Alternative Hypothesis ($H_{a}$)\n",
    "![difference](./img/giphy.gif)\n",
    "- claims the difference in the results due to the independent variable.\n",
    "\n",
    "- Alternative can be directional or non-directional.\n",
    "\n",
    "## Null Hypothesis ($H_{0}$)\n",
    "![the nothing](https://i1.wp.com/vidyasury.com/wp-content/uploads/2013/03/You_Rock_You_Rule.jpeg?resize=576%2C576&ssl=1)\n",
    "\n",
    "- $H_0$ should be logical complement of $H_{a}$.\n",
    "\n",
    "- That is to say: If Alternative is bidirectional than null-hypothesis claims no relation between independent and dependent variables\n",
    "\n",
    "- Alternative is directional (say claims a positive relation) then null claims there is no positive relation which means no effect or an effect in the opposite direction of the Alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $p$-Values\n",
    "\n",
    "The basic idea of a p-value is to quantify the probability that the results seen are in fact the result of mere random chance. This is connected with the null hypothesis since, if the null hypothesis is true and there is no significant correlation between the population variables X and Y, then of course any correlation between X and Y observed in our sample would have to be the result of mere random chance.\n",
    "\n",
    "### How Unlikely Is Too Unlikely?\n",
    "\n",
    "Suppose we calculate a p-value for some statistic we've measured (more on this below!) and we get a p-value of 20%. This would mean that there is a 20% chance that the results we observed were the result of mere random chance. Probably this is high enough that we ought _not_ to reject the null hypothesis that our variables are uncorrelated.\n",
    "\n",
    "In practice, a p-value _threshold_ of 5% is very often the default value for these tests of statistical significance. Thus, if it is calculated that the chance that the results we observed were actually the result of randomness is less than 1 in 20, then we would _reject_ the null hypothesis and _accept_ the alternative hypothesis.\n",
    "\n",
    "## Decision Rule - Significance Level ($\\alpha$)\n",
    "\n",
    "- if $H_{0}$ would be true what is the probability (p_value) of getting such experiment results by just chance. \n",
    "\n",
    "- If this probability is less than a critical pre-determined level $\\alpha$ (significance level - $\\alpha$ - value) then we reject the null hypothesis.\n",
    "\n",
    "- If the obtained probability $p_{value} \\leq \\alpha$: reject $H_{0}$\n",
    "\n",
    "- If the obtained probability $p_{value} \\geq \\alpha$: fail to reject $H_{0}$, retain $H_{0}$\n",
    "\n",
    "- Usually $\\alpha = 0.05$ - Let's talk what it means in action?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work with the normal distribution, since it's so useful. Suppose we are told that African elephants have weights distributed normally around a mean of 9000 lbs., with a standard deviation of 900 lbs. Pachyderm Adventures has recently measured the weights of 25 African elephants in Gabon and has calculated their average weight at 8637 lbs. They claim that these statistics on the Gabonese elephants are significant. Let's find out!\n",
    "\n",
    "What is our null hypothesis here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is our alternative hypothesis here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's set a threshold value of $p = 0.05$ for rejecting the null hypothesis.\n",
    "\n",
    "The standard error for our sample is: $\\large\\frac{\\sigma}{\\sqrt{n}}$\n",
    "\n",
    "lets define a function called `calc_se` using that formula!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 2 minutes to draft a function together to calc_se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elephant_sigma = None\n",
    "elephant_n = None\n",
    "\n",
    "se = calc_se(elephant_sigma, elephant_n)\n",
    "print(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And while we're at it, lets whip up a function called ```calc_z_score``` that represents this formula: $\\large\\frac{\\bar{x} - \\mu}{se}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 2 minutes to draft a function together to calc_z_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elephant_x_bar = None\n",
    "elephant_mu = None\n",
    "elephant_se = None\n",
    "\n",
    "zscore = calc_z_score(elephant_x_bar, elephant_mu, elephant_se)\n",
    "print(zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we've calculated the Z-score, we want to calculate the p value of that zscore using a cumulative distribution function(cdf).\n",
    "\n",
    "We use the CDF to determine the probability that a random observation that is taken from the population will be less than or equal to a certain value. You can also use this information to determine the probability that an observation will be greater than a certain value, or between two values.\n",
    "\n",
    "Lets use the [stats.norm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) package from scipy module to calculate the cdf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://matthew-brett.github.io/teaching/_images/on_cdfs-4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using stats' norm library, we can calculate the cdf with the zscore of a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (only open the bottom section after you've written some code above :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Looks like the 'area of the tail' corresponding to this z-score is only 2.2% which is < our 5% threshold value (our $\\alpha$).\n",
    "\n",
    "Great! That means we can reject our null hypothesis right? - since \"If the obtained probability $p_{value} \\leq \\alpha$: reject $H_{0}$\"\n",
    "\n",
    "Reviewing our null and alernative hypothesis we confirmed that we are comparing a non-directional change, and thus we need to account for both tails of the distribution.\n",
    "\n",
    "The area for both tails is thus 4.4%, still less than our 5% threshold value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Translation: </br>\n",
    "Given the null hypothesis is true, there is a 4.4% chance that the observed weight of the Gabonese elephants were the result of mere random chance. Because that is less than 5% (a 1-in-20 chance), we can confidently reject the null hypothesis and claim that the weight of the Gabonese elephants are statistically significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### note: we are **not accepting** the alternative, **merely rejecting** the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What could go wrong?\n",
    "What are the possible mistakes we can make just due to the construction of the algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type 1 Errors (False Positives) and Type 2 Errors (False Negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most tests for the presence of some factor are imperfect. And in fact most tests are imperfect in two ways: They will sometimes fail to predict the presence of that factor when it is after all present, and they will sometimes predict the presence of that factor when in fact it is not. Clearly, the lower these error rates are, the better, but it is not uncommon for these rates to be between 1% and 5%, and sometimes they are even higher than that. (Of course, if they're higher than 50%, then we're better off just flipping a coin to run our test!)\n",
    "\n",
    "Predicting the presence of some factor (i.e. counter to the null hypothesis) when in fact it is not there (i.e. the null hypothesis is true) is called a **\"false positive\"**. Failing to predict the presence of some factor (i.e. in accord with the null hypothesis) when in fact it is there (i.e. the null hypothesis is false) is called a **\"false negative\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.researchgate.net/profile/Joris_Meurs/publication/305265032/figure/fig6/AS:391272159301649@1470297960569/The-confusion-matrix-of-accepting-or-rejecting-the-null-hypothesis-H0-or-the.png\" width=1000px height=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![type error graph](https://dp8v87cz8a7qa.cloudfront.net/45396/5bd20d03240611540492547.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example\n",
    "\n",
    "Suppose I start flipping the same coin twice a day. What I'm curious about is whether the coin is fair or not.\n",
    "\n",
    "My null hypothesis will be that there is \"nothing to see here\", i.e. that the coin is after all fair. The alternative hypothesis will of course be that the coin is not.\n",
    "\n",
    "- **NH**: The coin is fair.\n",
    "- **AH**: The coin is biased.\n",
    "\n",
    "My statistical test will consist of flipping the coin a number of times and looking at those flips' results.\n",
    "\n",
    "If the coin is fair, then my test will result either in a true negative (accurate) or a false positive (inaccurate). If the coin is biased, then the test will result either in a true positive (accurate) or a false negative (inaccurate).\n",
    "\n",
    "Suppose that I set my value for $\\beta$. What I want to understand is how the threshold for rejection of the null hypothesis varies as a function of $\\beta$ and of the number of tosses $k$ that come up \"heads\".\n",
    "\n",
    "I want to write a function that will tell me, given inputs for $p$ and $k$, how many tosses I would need to make before I should reject the null hypothesis.\n",
    "\n",
    "We'll use the [.binom_test()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom_test.html) method in scipy's stats module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What number of tosses would I need to make before I should reject null hypothesis.\n",
    "# based on a given p_value\n",
    "\n",
    "def how_many_trials_to_reject_null(x, beta, p, test_alternative='two-sided'):\n",
    "    n = x                  #start the number of trials at the number of successes\n",
    "    \n",
    "    # .binom_test() needs the number of successes(x), the number of trials(n), \n",
    "    # the hypothesized probability of success(p), and indicate the type of alternative hypothesis\n",
    "    p_value = stats.binom_test(x, n, p, alternative=test_alternative)\n",
    "    \n",
    "    while p_value >= beta: # continue to calculate the p_value until its no longer >= beta\n",
    "        n += 1             # Increase the number of trials every loop.\n",
    "        p_value = stats.binom_test(x, n, p, alternative=test_alternative)\n",
    "        \n",
    "    return n               # Let us know how many trials we gotta do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test it out!\n",
    "how_many_trials_to_reject_null(1, beta=0.05, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "\n",
    "Given we only observe 1 'success' (a head), and assuming the null hypothesis that the coin is far is true, then it would take 9 trials before we could confidently reject the null hypothesis. \n",
    "\n",
    "### Lets checkout a [powerful visual](https://seeing-theory.brown.edu/probability-distributions/index.html) and overall top notch study sheet of what we tested above (chapter 3: CLT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Scenarios for Hypothesis Testing\n",
    "\n",
    "- Chemistry - do inputs from two different barley fields produce different\n",
    "yields?\n",
    "- Astrophysics - do star systems with near-orbiting gas giants have hotter\n",
    "stars?\n",
    "- Economics - demography, surveys, etc.\n",
    "- Medicine - BMI vs. Hypertension, etc.\n",
    "- Business - which ad is more effective given engagement?\n",
    "- Sports - [Do shoes predict marathon winners?](https://www.nytimes.com/interactive/2019/12/13/upshot/nike-vaporfly-next-percent-shoe-estimates.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1](./img/img1.png)\n",
    "\n",
    "![img2](./img/img2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-Distribution\n",
    "\n",
    "Student's t-distribution (or simply the t-distribution) is any member of a family of continuous probability distributions that arises when estimating the mean of a normally distributed population in situations where the sample size is small and the population standard deviation is unknown.\n",
    "\n",
    "![](https://www.geogebra.org/resource/xp7A3A53/uzHZ4VnO8dAwAMku/material-xp7A3A53.png)\n",
    "\n",
    "The fatter tails of a T distribution represent larger p values. \n",
    "\n",
    "But as ```n``` increases past 30, the distribution starts to resemble a normal Z distribution. by n=1000 they are vitually indistinguishable \n",
    "\n",
    "![](https://www.researchgate.net/profile/Demetris_Christopoulos/post/What_is_the_rationale_behind_the_magic_number_30_in_statistics/attachment/59d6280bc49f478072e9b8f6/AS%3A272429056757760%401441963556404/download/student_normal_30.jpg)\n",
    "\n",
    "<img src=\"img/df.png\" width=\"550\">\n",
    "\n",
    "- Consider the case: We have a sample of 4 elements [2, 8, 5, A]. We don't know A but we know the $\\bar{x} = 6$. Can we find A? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-Tests\n",
    "\n",
    "### Why use it?\n",
    "- Sometimes the population standard deviation is irrelevant, and sometimes it’s\n",
    "unknown. (we’ll get to the different types of t-test later)\n",
    "- Sometimes a sample is too small to be confident that it’s an accurate representation of reality\n",
    "\n",
    "### T vs Z (again)\n",
    "\n",
    "A t-test is like a modified z-test:\n",
    "- Penalize for small sample size - “degrees of freedom”\n",
    "- Use sample std. dev. (```s```) to estimate population σ\n",
    "\n",
    "![img5](./img/img5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Review\n",
    "### Language of Hypothesis Testing\n",
    "\n",
    "- If p < α : we *reject* the null hypothesis<br>\n",
    "- If p > α : we *fail to reject* the null hypothesis\n",
    "\n",
    "Language is **important**\n",
    "\n",
    "### What if the experiment fails?\n",
    "\n",
    "- Don’t throw out failed experiments\n",
    "- This methodology, with this data, does not produce significant results\n",
    " - More data\n",
    " - More time\n",
    " - More details\n",
    "\n",
    "### T-test success recipe\n",
    "\n",
    "Regardless of the type of t-test you are performing, there are 5 main steps to executing them:\n",
    "\n",
    "- Set up null and alternative hypotheses\n",
    "\n",
    "- Choose a significance level\n",
    "\n",
    "- Calculate the test statistic\n",
    "\n",
    "- Determine the critical or p-value (find the rejection region)\n",
    "\n",
    "- Compare t-value with critical t-value to accept or reject the Null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Is this any difference from population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean = 85\n",
    "sample_data = [90,100,110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `scipi.stats` to import the appropriate ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Manual implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from statistics import stdev\n",
    "\n",
    "data = [90,100,110]\n",
    "mu = 85\n",
    "n = len(data)\n",
    "s = stdev(data)\n",
    "df = n-1\n",
    "\n",
    "t = (100-85)/(s/(n**.5))\n",
    "print(t, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "I'm buying jeans from store A and store B.  I know nothing about their inventory other than prices. Should I go just one store for a less expensive pair of jeans?\n",
    "I'm pretty apprehensive about this big decision so alpha = 0.10\n",
    "\n",
    "Try this both manually and with scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store1 = [20,30,30,50,75,25,30,30,40,80]\n",
    "store2 = [60,30,70,90,60,40,70,40]\n",
    "\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Given the same data 1, how many more samples would you need to achieve p = 0.01, assuming sample mean and sample std. dev. do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [90,100,110]\n",
    "mu = 85\n",
    "s = None\n",
    "n = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
