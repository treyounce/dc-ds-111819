{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Agenda__\n",
    "\n",
    "- Difference between population and sample\n",
    "- How can we get a good sample?\n",
    "- Point estimators from sample\n",
    "- Sampling distribution, especially sampling distribution of the mean\n",
    "- Central Limit Theorem - statement and use of it.\n",
    "- Creating confidence intervals around sample mean using CLT\n",
    "- Recap\n",
    "\n",
    "\n",
    "# Sampling Distributions\n",
    "\n",
    "## Population vs Sample\n",
    "\n",
    "__population__ A population is the set of all elements of interest in a study. (Finite population and infinite population)\n",
    "\n",
    "__sample__ A sample is a subset of the population.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "The mayor's office has hired Flatiron Data Science Immersive students to determine a way to fix traffic congestion. A good starting point is to determine out what proportion of the population of DC owns a car.\n",
    "\n",
    "In order for us to make any determinations about a population, we must first get information about it.\n",
    "\n",
    "Because it's impractical to ever usually get data about *everyone* in a population, we must take a sample.\n",
    "\n",
    "Our sample should be:\n",
    "\n",
    "* Randomly selected- every item should have an *equal* chance of being selected\n",
    "* Representative of our population\n",
    "\n",
    "![pop](./img/sample_pop.png)\n",
    "\n",
    "\n",
    "**Random sampling is not easy to do, let's look at an example:**\n",
    "\n",
    "Imagine you are trying to determine what proportion of DC metro area people own a car\n",
    "\n",
    "* Stand outside of Flatiron at 12 pm and ask random people until *n* responses\n",
    "\n",
    "\n",
    "* Go to a randomly assigned street corner and at a random time and ask *n* people if they own a car\n",
    "\n",
    "\n",
    "__Objective of Sampling__\n",
    "\n",
    "When we gather a sample, we are trying to minimize the bias of our sample while also minimizing our cost.\n",
    "\n",
    "\n",
    "## Point Estimates\n",
    "\n",
    "!! Very important observation!!: We can consider random sampling as an 'random experiment' and then when we calculate mean, variance, standard deviation, median etc. these are functions on the outcomes of this experiment. We have a name for such functions can you remember it?\n",
    "\n",
    "![imgsample](./img/sample_stats.png)\n",
    "\n",
    "### It's your turn :)\n",
    "\n",
    "[Download data](https://www.kaggle.com/ishaanv/ISLR-Auto)\n",
    "\n",
    "[UCI-repo](https://archive.ics.uci.edu/ml/datasets/auto+mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "auto  = pd.read_csv('data/auto-mpg.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a random sample of 30 cars from auto dataset and find both sampling and population mean and standard deviation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 1-5 supplement.py\n",
    "sampled_data = auto.sample(n = 20, random_state=110719)\n",
    "x_bar = sampled_data.mpg.mean()\n",
    "mu = auto.mpg.mean()\n",
    "\n",
    "s_hat = sampled_data.mpg.std()\n",
    "sigma = auto.mpg.std(ddof = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Sampling mean is {} \n",
    "        \\nPopulation mean is {}\\n\"\"\".format(x_bar, mu))\n",
    "\n",
    "print(\"\"\"Sampling std is {} \n",
    "        \\nPopulation std is {}\"\"\".format(s_hat, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the sample mean and the population mean is known as the **Sampling Error**.  \n",
    "\n",
    ">When using the sample mean to estimate the population mean, some possible error will be involved since random sample means are also random.\n",
    "\n",
    "### It's your turn again :)\n",
    "\n",
    "Repeat the sampling process you did above 1000 times and plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 9-22 supplement.py\n",
    "# taking repeating samples from auto dataset\n",
    "thousand_rand_samp = [auto.sample(n = 20).mpg.mean() for i in range(1000)]\n",
    "\n",
    "bars = plt.hist(thousand_rand_samp)\n",
    "\n",
    "plt.vlines(x = mu, ymin= 0,\n",
    "           ymax = bars[0].max() +1,\n",
    "           color = 'r', label = 'pop mean')\n",
    "plt.xticks(range(17,29))\n",
    "plt.xlabel('sample_means')\n",
    "plt.ylabel('frequencies of sample means')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thousand_rand_samp = [auto.sample(n = 50).mpg.mean() for i in range(1000)]\n",
    "\n",
    "bars = plt.hist(thousand_rand_samp)\n",
    "\n",
    "plt.vlines(x = mu, ymin= 0,\n",
    "           ymax = bars[0].max() +1,\n",
    "           color = 'r', label = 'pop mean')\n",
    "plt.xticks(range(17,29))\n",
    "plt.xlabel('sample_means')\n",
    "plt.ylabel('frequencies of sample means')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Limit Theorem\n",
    "\n",
    "The Central Limit Theorem states: \n",
    ">When you add **a large number** of independent random variables, irrespective of the original distribution of these variables, **their sampling mean distribution tends towards a normal distribution** with mean equals to the mean of the original population and the standard deviation equals to $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The standard error of the mean is the standard deviation of the sampling distribution.\n",
    "The issue is that a sample is not an exact replica of the population. We need to account for the fact that in order to make our estimate of the $\\mu$ value possible. Let's break it down:\n",
    "\n",
    "## Standard Error\n",
    "\n",
    "$$\\sigma _{\\bar{X}} = \\frac{\\sigma }{\\sqrt{n}}$$\n",
    "\n",
    "* $ \\sigma _{x}$ = standard error of $\\bar{x} $\n",
    "* $ \\sigma $ = standard deviation of population\n",
    "\n",
    "\n",
    "**What if we do not know the population sigma?**<br>\n",
    "If we do not know the population standard deviation, we can approximate for it by used the sample standard deviation.\n",
    "\n",
    "$\\sigma _{x} â‰ˆ \\frac{s}{\\sqrt{n}}$\n",
    "\n",
    "* s = sample standard deviation\n",
    "\n",
    "But in this case, distribution shape is not 'normal' anymore. In this case the shape will be call 'T-distribution'. We will study this later in more details.\n",
    "\n",
    "\n",
    "**Sample size impact on standard error of mean**<br>\n",
    "\n",
    "Q: How should sample size influence standard error of the mean?\n",
    "\n",
    "\n",
    "![error](./img/diminishing_error.png)\n",
    "Important implication: The Standard Error of the mean remains the same as long as the population standard deviation is known and sample size remains the same.\n",
    "\n",
    "\n",
    "__Note-1__ In the case of finite sampling, we need to adjust the formula for standard error:\n",
    "\n",
    "<img src=\"img/standard_deviation_of_x_bar.png\" width=\"650\">\n",
    "\n",
    "\n",
    "__Note-2__ Note that in CLT the shape of initial distribution is not important! With enough sample size we can always achieve a distribution very close to normal one.\n",
    "\n",
    "<img src=\"img/clt_with_different.png\" width=\"650\">\n",
    "\n",
    "\n",
    "## Interval Estimation - Confidence Intervals\n",
    "\n",
    "Q: Let's assume that we have a sample of size=49 and we know the standard deviation of the population is $\\sigma = 5$. If we know that sampling mean is $\\bar{x} = 20$. What might be a good estimate for the population mean if we also know that the population mean is bigger than 20?\n",
    "\n",
    "Hint: What do we mean by 'a good estimate'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#suppose population mu is 21\n",
    "mu = 21\n",
    "# sample mean gives us a point estimator\n",
    "point_estimator = 20\n",
    "\n",
    "# we know population variance is 49\n",
    "std_error = 5/(np.sqrt(49))\n",
    "\n",
    "\n",
    "# how much confidence do we require\n",
    "confidence = 0.95\n",
    "\n",
    "# alpha \n",
    "alpha = 1- confidence\n",
    "\n",
    "# due to symmetry we divided alpha by 2\n",
    "# note that to find z_alpha_over_2 we used \n",
    "# standard normal distribution\n",
    "\n",
    "z_alpha_over_2 = np.abs(stats.norm.ppf(alpha/2))\n",
    "\n",
    "print(z_alpha_over_2)\n",
    "\n",
    "\n",
    "# upper bound gives us a value so that\n",
    "# 2*(the area between point_estimator - upper_bound) = confidence\n",
    "\n",
    "upper_bound = point_estimator + z_alpha_over_2* std_error\n",
    "\n",
    "# now let's plot these\n",
    "\n",
    "# a normal distribution with mean=mu and std=sigma\n",
    "x = np.linspace(mu - 4*std_error, mu + 4*std_error, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, std_error))\n",
    "\n",
    "# a vertical line to mark point estimator\n",
    "plt.vlines(point_estimator, ymin=0,\n",
    "           ymax = stats.norm.pdf(point_estimator, mu, std_error))\n",
    "\n",
    "# a vertical line for population mu\n",
    "plt.vlines(mu, ymin=0,\n",
    "           ymax = stats.norm.pdf(mu, mu, std_error),\n",
    "          color = 'g')\n",
    "\n",
    "# a vertical line for upper bound\n",
    "plt.vlines(upper_bound, ymin=0,\n",
    "           ymax = stats.norm.pdf(upper_bound, \n",
    "                                 mu, std_error))\n",
    "\n",
    "\n",
    "# fill the area between upper_bound and point_estimator\n",
    "plt.fill_between(x= np.linspace(point_estimator, upper_bound, 100), \n",
    "                 y1= stats.norm.pdf(np.linspace(point_estimator,\n",
    "                                                upper_bound, 100), mu, std_error) ,\n",
    "                 facecolor='blue',\n",
    "                 alpha=0.35, \n",
    "                 label= 'btwn point estimator and\\n upper bound')\n",
    "\n",
    "# fill the area between point estimator and the left of it\n",
    "plt.fill_between(x= np.linspace(mu - 4*std_error, point_estimator, 100), \n",
    "                 y1= stats.norm.pdf(np.linspace(mu - 4*std_error, point_estimator,100), mu, std_error) ,\n",
    "                 facecolor='red',\n",
    "                 alpha=0.35, \n",
    "                 label= 'red area %.3f'%(stats.norm.cdf(point_estimator, mu, std_error)))\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Z-scores](https://www.mathsisfun.com/data/standard-normal-distribution-table.html)\n",
    "\n",
    "<img src=\"img/interval_estimation.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing \n",
    "\n",
    "## The Analytical Question \n",
    "\n",
    "A data scientist wants to examine if there is an effect on IQ scores when using tutors. To analyze this, she conducts IQ tests on a sample of 40 students, and wants to compare her students' IQ to the general population IQ. The way an IQ score is structured, we know that a standardized IQ test has a mean of 100, and a standard deviation of 16. When she tests her group of students, however, she gets an average IQ of 103. Based on this finding, does tutoring make a difference?\n",
    "\n",
    "## Step 1: State Your Hypotheses\n",
    "\n",
    "### The Alternative Hypothesis ($H_a$)\n",
    "\n",
    "The alternative hypothesis always reflects the idea or theory that needs to be tested. For this problem, you want to test if the tutoring has resulted in a significant increase in student IQ. So, you would write it down as:\n",
    "\n",
    "> The sample mean is **significantly** bigger than the population mean\n",
    "\n",
    "Again, significance is key here. If we denote sample mean as $\\bar{x}$, and population mean as mu ($\\mu$), you can write the alternative hypothesis as:\n",
    "\n",
    "$$\\large H_a\\text{:   }\\mu < \\bar{x}$$\n",
    "\n",
    "The alternative hypothesis here is that $\\mu$ is less than $M$. In other situations, you could check for both possibilities of $\\mu$ being smaller OR bigger than by checking  $\\mu \\neq M$. \n",
    "\n",
    "Maybe the tutoring results as a lower IQ... Who knows!\n",
    "\n",
    "For now, you'll just check for the **significant increase**, for now, to keep the process simple.\n",
    "\n",
    "### The Null Hypothesis ($H_0$)\n",
    "\n",
    "For a one-sample z-test, you define your null hypothesis as there being **no significant difference** between specified sample and population. This means that under the null hypothesis, you assume that any observed (generally small) difference may be present due to sampling or experimental error. Considering this, for this problem, you can define a null hypothesis ($H_0$) as:\n",
    "\n",
    "> There is **no significant difference** between the sample mean and population mean \n",
    "\n",
    "Remember the emphasis is on a _significant_ difference, rather than just any difference as a natural result of taking samples.\n",
    "\n",
    "Denoting the sample mean as $M$, and the population mean as mu ($\\mu$), you can write the null hypothesis as:\n",
    "\n",
    "$$\\large H_0\\text{:   }\\mu \\geq \\bar{x}$$\n",
    "\n",
    "\n",
    "## Step 2: Specify a Significance Level (alpha)\n",
    "\n",
    "Now that your hypotheses are in place, you have to decide on your significance level alpha ($\\alpha$) as a cut-off value to define whether you can reject your null hypothesis or not.\n",
    "\n",
    "As discussed previously, often, $\\alpha$ is set to 0.05, which also has as a side-effect that there is a 5 percent chance that you will reject the null hypothesis when it is true.\n",
    "Later, you'll see that using alpha, you'll formulate your test result as: \"with a confidence level of 95%, we can state that...\". For a z-distribution, this can be shown as below:\n",
    "\n",
    "<img src=\"img/hypothesis_test.png\" width=670>\n",
    "\n",
    "\n",
    "If you test both sides of the distribution ($\\mu \\neq \\bar{x}$, when $\\mu$ can either be smaller OR bigger), you need to perform a 2-tail test to see if tutoring lowers OR highers the IQ of students.\n",
    "\n",
    "Each red region would be calculated as $\\dfrac{\\alpha}{2}$. When testing of a single side (as in the example) i.e. just higher OR just lower, you can use a one-tail test as shown in the first and second images. The $\\alpha$ value we use is 0.05 or $5\\%$.\n",
    "\n",
    "## Step 3: Calculate the test statistic\n",
    "\n",
    "For z-tests, a z-statistic is used as our test statistic. You'll see other statistics suitable for other tests later. A one-sample z-statistic is calculated as:\n",
    "\n",
    "$$ \\large \\text{z-statistic} = \\dfrac{\\bar x - \\mu_0}{{\\sigma}/{\\sqrt{n}}} $$\n",
    "\n",
    "This formula slightly differs from the standard score formula. It includes the square square root of n to reflect that we are dealing with the sample variance here. \n",
    "\n",
    "Now, all you need to do is use this formula given your sample mean $\\bar x$, the population standard deviation $\\sigma$, and the number of items in the sample ($n$). $\\mu_0$ is the mean you're testing the hypothesis for, or the \"hypothesized mean\". \n",
    "\n",
    "Let's use Python to calculate this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
