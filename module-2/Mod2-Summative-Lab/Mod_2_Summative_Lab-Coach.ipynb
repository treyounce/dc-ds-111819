{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completion of this lab, each unique team in this dataset should have a record in the MongoDB instance containing the following information:\n",
    "\n",
    "- The name of the team\n",
    "- The total number of goals scored by the team during the 2011 season\n",
    "- The total number of wins the team earned during the 2011 season\n",
    "- A histogram visualization of the team's wins and losses for the 2011 season (store the visualization directly)\n",
    "- The team's win percentage on days where it was raining during games in the 2011 season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in the Data we need from our SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('database.sqlite')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c.execute('''SELECT name, type FROM sqlite_master\n",
    "''').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "SELECT * FROM Matches\n",
    "LIMIT 1''').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's grab all matches from the 2011 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''\n",
    "SELECT * FROM Matches\n",
    "WHERE Season LIKE '2011'\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to a pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df = pd.DataFrame(c.fetchall())\n",
    "\n",
    "matches_df.columns = [i[0] for i in c.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find the winning team in each match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winning_team(x):\n",
    "    if x['FTR'] == 'D':\n",
    "        return 'Draw'\n",
    "    elif x['FTR'] == 'H':\n",
    "        return x['HomeTeam']\n",
    "    else:\n",
    "        return x['AwayTeam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df['Winner'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_df.apply(winning_team, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df['Winner'] = matches_df.apply(winning_team, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up away and home win/loss/draw information to use groupby later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def away_wins(x):\n",
    "    if x['FTR'] == 'A':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_wins(x):\n",
    "    if x['FTR'] == 'H':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draws(x):\n",
    "    if x['FTR'] == 'D':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def away_losses(x):\n",
    "    if x['FTR'] != 'A' and x['FTR'] != 'D':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_losses(x):\n",
    "    if x['FTR'] != 'H' and x['FTR'] != 'D':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df['away_wins'] = matches_df.apply(away_wins, axis = 1)\n",
    "\n",
    "matches_df['home_wins'] = matches_df.apply(home_wins, axis = 1)\n",
    "\n",
    "matches_df['draws'] = matches_df.apply(draws, axis = 1)\n",
    "\n",
    "matches_df['away_losses'] = matches_df.apply(away_losses, axis = 1)\n",
    "\n",
    "matches_df['home_losses'] = matches_df.apply(home_losses, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check if our groupby now works to get the total wins, draws, and losses for each team "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wins and draws at HOME per team\n",
    "\n",
    "matches_df.groupby(['HomeTeam'])[['home_wins', 'draws', 'home_losses']].sum().loc['Arsenal', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wins and draws AWAY per team\n",
    "\n",
    "matches_df.groupby(['AwayTeam'])[['away_wins', 'draws', 'away_losses']].sum().loc['Arsenal', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can make sure our numbers are correct. I will use Arsenal's record as a check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to our groupbys Arsenal played 19 home games, and 19 away games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total home games played\n",
    "\n",
    "matches_df.groupby(['HomeTeam'])['home_wins'].count()['Arsenal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total away games played\n",
    "\n",
    "matches_df.groupby(['AwayTeam'])['away_wins'].count()['Arsenal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### They had 12 wins and 4 draws at home, which leaves them with a 12 - 4 - 3 record\n",
    "#### They had 9 wins and 3 draws away, which leaves them with a 9-3-7 record\n",
    "#### Adding these up gives a 21-7-10 record which is correct based on a Google search of Arsenal's 2011-2012 record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby to calculate home and away losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_df.groupby(['HomeTeam'])['home_wins'].count() - (matches_df.groupby(['HomeTeam'])['home_wins'].sum() + \n",
    "                                                         matches_df.groupby(['HomeTeam'])['draws'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_df.groupby(['AwayTeam'])['away_wins'].count() - (matches_df.groupby(['AwayTeam'])['away_wins'].sum() + \n",
    "                                                         matches_df.groupby(['AwayTeam'])['draws'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing data from our API. We need to add rain data before aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berlin lat/long 52.5200° N, 13.4050° E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_api_key = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unneeded info\n",
    "\n",
    "currently\n",
    "minutely\n",
    "hourly\n",
    "alerts\n",
    "flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.api.get(\n",
    "    f'https://api.darksky.net/forecast/{ds_api_key}/52.52,13.405,2018-05-13T10:00:00?exclude=hourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "req.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req.json()['daily']['data'][0]['precipIntensityMax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_df['Date'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check our API request count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_df['Date'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write API Request function. We are just populating a list with precipIntensityMax for each day. If it's > 0, we will keep that as a rainy day. 0 is non-rainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_precip_info(ds_api_key, date_list):\n",
    "    output_list = []\n",
    "    for date in date_list:\n",
    "        req = requests.api.get(\n",
    "            f'https://api.darksky.net/forecast/{ds_api_key}/52.52,13.405,{date}T10:00:00?exclude=hourly')\n",
    "        output_list.append(req.json()['daily']['data'][0]['precipIntensityMax'])\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run our function and set variable to our list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_on_date = grab_precip_info(ds_api_key, matches_df['Date'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a rain df with unique IDs (we will join this with our main df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rain_df = pd.DataFrame(rain_on_date, matches_df['Date'].unique())\n",
    "\n",
    "rain_df = rain_df.rename(columns = {0 : 'rainfall'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set our matches_df index as date and join our tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df = matches_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_rainfall_df = matches_df.join(rain_df, on = matches_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_rainfall_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that our merge worked properly. Every 2011-01-15 match is getting the same rainfall number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_rainfall_df.loc['2012-03-31', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a boolean column for rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_rainfall_df['rainfall_bool'] = matches_rainfall_df['rainfall'] != False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_rainfall_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need the home and away wins when raining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def away_wins_rain(x):\n",
    "    if x['FTR'] == 'A' and x['rainfall_bool']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_wins_rain(x):\n",
    "    if x['FTR'] == 'H' and x['rainfall_bool']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_rainfall_df['away_wins_rain'] = matches_rainfall_df.apply(away_wins_rain, axis = 1)\n",
    "\n",
    "matches_rainfall_df['home_wins_rain'] = matches_rainfall_df.apply(home_wins_rain, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_rainfall_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create home and away dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "home_df = matches_rainfall_df.groupby('HomeTeam').sum()[['home_wins', 'draws', 'home_losses', 'FTHG', \n",
    "                                               'home_wins_rain', 'rainfall_bool']]\n",
    "\n",
    "away_df = matches_rainfall_df.groupby('AwayTeam').sum()[['away_wins', 'draws', 'away_losses', 'FTAG', \n",
    "                                               'away_wins_rain', 'rainfall_bool']]\n",
    "\n",
    "home_df.columns = ['wins', 'draws', 'losses', 'goals', 'wins_rain', 'rainfall_bool']\n",
    "\n",
    "away_df.columns = ['wins', 'draws', 'losses', 'goals', 'wins_rain', 'rainfall_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "away_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = home_df + away_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['rain_win_percent'] = final_df['wins_rain'] / final_df['rainfall_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create \"histograms\" aka bar charts - I would argue that these aren't really histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_loss_graphs = []\n",
    "for count, team in enumerate(final_df.index):\n",
    "    fig = plt.figure(count)\n",
    "    (plt.bar(x = ['wins', 'losses'], height = [final_df.loc[team, 'wins'], final_df.loc[team, 'losses']], \n",
    "            color = ['red', 'blue']))\n",
    "    win_loss_graphs.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(win_loss_graphs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we need to convert this list to binary or bson, so it can be read into a Mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_figs = []\n",
    "for item in win_loss_graphs:\n",
    "    item.savefig('myfile.png')\n",
    "    with open(\"myfile.png\", \"rb\") as image:\n",
    "        f = image.read()\n",
    "    binarized_figs.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['graph'] = binarized_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset index so the Team Name is properly stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put our records in our Mongo database with PyMongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start db\n",
    "myclient = pymongo.MongoClient('mongodb://127.0.0.1:27017')\n",
    "mydb = myclient['team_database']\n",
    "mycollection = mydb['matches_collection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prep records for db\n",
    "final_dict = final_df.to_dict(orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add records to db\n",
    "insertion_results = mycollection.insert_many(final_dict)\n",
    "insertion_results.inserted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call db\n",
    "get_db = myclient.get_database('team_database')\n",
    "\n",
    "my_matches = get_db.get_collection('matches_collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = my_matches\n",
    "\n",
    "rebuild_df = []\n",
    "for document in cursor.find():\n",
    "    rebuild_df.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_back = pd.DataFrame(rebuild_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_back.loc[0,'graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "image = Image.open(io.BytesIO(df_back.loc[0,'graph']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient.drop_database(mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
